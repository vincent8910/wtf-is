# LLM（大型語言模型） — 讀過超大量文字、能跟你對話的 AI

> **白話說：** 想像一個人讀遍了整個網路上的文章、書籍、對話紀錄，然後你問他什麼他都能回答。LLM 就是這樣一個「讀過整個圖書館」的 AI。

---

## 它到底是什麼？

LLM 是 Large Language Model 的縮寫，中文叫「大型語言模型」。

它是一種用超大量文字資料 [訓練](training.md) 出來的 AI [模型](model.md)。「大型」指的是：
- **資料量超大**：幾乎讀遍了整個網路上的公開文字
- **參數量超大**：模型裡有幾百億甚至幾兆個可調整的參數

你最熟悉的 LLM 就是 ChatGPT、Claude、Gemini 這些。

LLM 的核心能力是「給你一段文字，它能接下去寫」。這聽起來很簡單，但當模型夠大、資料夠多，它就能做到翻譯、寫程式碼、寫文章、回答問題、摘要、分析⋯⋯幾乎所有跟文字有關的事。

## 生活比喻 / 實際例子

想像一個超級博學的朋友：

- 他讀過所有維基百科、所有新聞、所有小說、所有論壇討論
- 你問他「義大利麵要怎麼煮」，他能詳細回答
- 你問他「幫我寫一封請假信」，他也能幫你寫
- 但他偶爾會「很有自信地說錯」——因為他是根據讀過的文字推測的，不是真正理解（這叫 [Hallucination](hallucination.md)）

實際會聽到的說法：
- 「ChatGPT 是 OpenAI 開發的 **LLM**」
- 「我們要評估哪個 **大型語言模型** 最適合我們的需求」
- 「這個 **LLM** 的中文能力比較好」

## 為什麼要知道這個詞？

LLM 是目前 AI 領域最紅的詞之一。ChatGPT、Claude、Gemini、LLaMA 都是 LLM。只要聊到「生成式 AI」「AI 聊天機器人」，背後就是 LLM。了解它，你就能參與大部分的 AI 話題。它基於 [Transformer](transformer.md) 架構，常搭配 [Prompt Engineering](prompt-engineering.md)、[Fine-tuning](fine-tuning.md)、[RAG](rag.md) 使用。

---
**[← 回到 AI / 機器學習總覽](../README.md)**
