# Bias（偏差） — AI 學到了資料裡的偏見，做出不公平的判斷

> **白話說：** 如果你只讓 AI 看男生當工程師的資料，它就會「學到」工程師 = 男生。Bias 就是 AI 從不均衡的資料中學到的偏見。

---

## 它到底是什麼？

Bias 在 AI 中指的是模型因為 [訓練](training.md) 資料的不均衡或偏頗，而做出帶有偏見的判斷。

AI 不會自己產生偏見——它的偏見來自人類餵給它的資料。如果資料本身有問題，AI 就會「學到」這些問題。

真實發生過的案例：
- **履歷篩選 AI**：因為過去被錄取的大多是男性，AI 就自動給女性較低分
- **人臉辨識 AI**：因為訓練資料大多是白人面孔，辨識深色皮膚的人就容易出錯
- **貸款審核 AI**：因為歷史資料反映了過去的歧視，AI 繼續做出歧視性判斷

這不是 AI「故意」歧視，而是它忠實地學會了資料裡的偏見。

## 生活比喻 / 實際例子

想像你在訓練一個新的美食評審：

- 你只讓他吃台灣料理，從來沒讓他吃過其他國家的食物
- 他就會認為「好吃 = 台灣味」，所以給泰國菜打低分、義大利菜也打低分
- 他不是故意的，只是他的「經驗」（訓練資料）有偏差

AI 的 Bias 也是一樣——它的「經驗」就是訓練資料，資料偏了，判斷就偏了。

實際會聽到的說法：
- 「這個 AI 有 **Bias** 問題，對某些族群不公平」
- 「我們要檢查 [資料集](dataset.md) 有沒有 **偏差**」
- 「AI 倫理最大的議題之一就是 **Bias**」

## 為什麼要知道這個詞？

AI 不是中立的。如果你的公司在用 AI 做任何涉及「判斷人」的事（招聘、貸款、保險、內容審核），Bias 就是你必須關注的議題。這不只是技術問題，更是倫理和法律問題。它跟 [Dataset](dataset.md)、[Hallucination](hallucination.md) 同屬 AI 的重要風險議題。

---
**[← 回到 AI / 機器學習總覽](../README.md)**
