# Dataset（資料集） — AI 學習用的「教材」，沒有好教材就教不出好學生

> **白話說：** 就像學生的課本和練習題。AI 的學習全靠資料集——資料越多越好、越乾淨越好、越多樣越好。

---

## 它到底是什麼？

Dataset 就是一堆整理好的資料，拿來 [訓練](training.md) AI 用的。

不同的任務需要不同的 Dataset：
- 訓練辨識貓狗的 AI → 需要幾萬張標好「貓」或「狗」的照片
- 訓練翻譯 AI → 需要幾百萬組「中文句子 ↔ 英文句子」的對照
- 訓練聊天 AI → 需要海量的對話紀錄和文章

Dataset 的品質直接決定 AI 的好壞：
- **資料太少** → AI 學不夠，表現差
- **資料有錯** → AI 學到錯的東西
- **資料不均衡** → AI 產生 [Bias（偏差）](bias.md)
- **資料品質高** → AI 表現好

所以在 AI 領域有一句話：「Garbage in, garbage out」（垃圾進，垃圾出）。

## 生活比喻 / 實際例子

想像你要培訓一個新人辨識假鈔：

- **好的 Dataset**：給他看 1000 張真鈔、1000 張假鈔，每張都標好、品質清楚
- **差的 Dataset**：只給他看 10 張，而且其中幾張模糊不清、有幾張標錯

用哪種教材訓練出來的員工比較厲害？當然是前者。

實際會聽到的說法：
- 「我們的 **Dataset** 太小了，模型效果不好」
- 「先做 data cleaning 把 **資料集** 清乾淨」
- 「這個 **Dataset** 有 [Bias](bias.md)，女性樣本太少了」
- 「公開的 **Dataset** 不夠用，我們要自己標資料」

## 為什麼要知道這個詞？

「AI 好不好用」很大程度取決於 Dataset 的品質。如果你的公司要導入 AI，第一步不是選模型，而是「我們有沒有足夠好的資料？」。理解 Dataset 的重要性，你就知道為什麼資料工程師和資料標註這麼重要。它跟 [Training](training.md)、[Overfitting](overfitting.md)、[Bias](bias.md) 直接相關。

---
**[← 回到 AI / 機器學習總覽](../README.md)**
