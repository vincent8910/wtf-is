# Training（訓練） — 讓 AI 從大量資料中學習的過程

> **白話說：** 就像讓一個新人反覆練習、看案例、做模擬考，直到他學會為止。AI 的訓練就是讓電腦不斷看資料、調整自己，直到能做出正確判斷。

---

## 它到底是什麼？

Training（訓練）是打造 AI [模型](model.md) 最關鍵的步驟。

過程大概是這樣的：
1. 準備大量的 [資料集](dataset.md)（比如十萬張有標記的貓狗照片）
2. 把資料丟給 [演算法](algorithm.md) 去學習
3. 電腦一開始會亂猜，猜錯了就調整自己的參數
4. 反覆幾百萬次之後，猜得越來越準
5. 訓練完成，得到一個可以用的 [模型](model.md)

訓練需要大量的運算資源（GPU）和時間。像 ChatGPT 這種大型模型，據說訓練一次要花上千萬美金的電費和算力。

## 生活比喻 / 實際例子

想像你在教一個小孩學騎腳踏車：

- 一開始他一定會摔倒（猜錯）
- 你在旁邊扶著、告訴他「身體要平衡」（給回饋）
- 他摔了一百次，每次都調整一點點
- 最後他會騎了（模型訓練完成）

訓練結束後，他就算遇到沒走過的路也能騎——這就像模型能處理沒見過的新資料。

實際會聽到的說法：
- 「這個模型還在 **Training**，大概要跑三天」
- 「**訓練** 資料不夠多，模型效果不好」
- 「我們需要更多 GPU 來加速 **Training**」

## 為什麼要知道這個詞？

只要聊到 AI，就會聊到訓練。為什麼 AI 公司要花那麼多錢？為什麼需要那麼多資料？為什麼 GPU 這麼貴？答案都跟「訓練」有關。理解這個概念，你就能理解 AI 產業的成本結構。它跟 [Overfitting](overfitting.md)、[Dataset](dataset.md) 直接相關。

---
**[← 回到 AI / 機器學習總覽](../README.md)**
